{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2af402f-a7dd-41e9-862c-5c628709447c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import noisereduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import torchaudio.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import skimage.io\n",
    "import cv2\n",
    "\n",
    "\n",
    "directory = '../spectrograms/'\n",
    "\n",
    "def extract_from_filename(filename):\n",
    "    filename = filename.replace('.wav', '')\n",
    "    parts = filename.split('_')\n",
    "    print(parts)\n",
    "    speaker_id = parts[0]\n",
    "    gender = 'female' if speaker_id[0] == 'f' else 'male'\n",
    "    script_id = parts[1]\n",
    "    if len(parts) > 3 and not parts[3][0].isdigit():\n",
    "        recording_type = '_'.join(parts[2:4])\n",
    "    else:\n",
    "        recording_type = parts[2]\n",
    "    return speaker_id, script_id, gender, recording_type\n",
    "#TODO why second empty\n",
    "def plot_waveform(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    print(plt.subplots(num_channels, 1))\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        # axes[c].set_xlim([0, 30])\n",
    "    figure.suptitle(\"waveform\")\n",
    "\n",
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\"):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        # axes[c].set_xlim([0, 15])\n",
    "        # axes[c].set_ylim([0, 1500])\n",
    "    figure.suptitle(title)        \n",
    "\n",
    "class_one = ['f1', 'f7', 'f8', 'm3', 'm6', 'm8']\n",
    "data = []\n",
    "\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.startswith('.'):\n",
    "#         continue\n",
    "#     if filename.endswith('.png'):\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "        \n",
    "#         try:\n",
    "#             speaker_id, script_id = extract_from_filename(filename)\n",
    "#             # samples = waveform.numpy().flatten()\n",
    "\n",
    "#             is_class_one = any(s in filepath for s in class_one)\n",
    "\n",
    "#             img = cv2.imread(filepath)\n",
    "#             gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#             hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "            \n",
    "#             plt.plot(hist)\n",
    "#             # label the x-axis\n",
    "#             plt.xlabel('Pixel Intensity')\n",
    "#             # label the y-axis\n",
    "#             plt.ylabel('Number of Pixels')\n",
    "#             # display the title\n",
    "#             plt.title('Grayscale Histogram')\n",
    "            \n",
    "#             plt.show()\n",
    "            \n",
    "\n",
    "#             # dest1 = '../sliced_spectograms/1'\n",
    "#             # dest2 = '../sliced_spectograms/0'\n",
    "\n",
    "#             # if is_class_one:\n",
    "#             #     os.rename(filepath,os.path.join(dest1,filename))\n",
    "#             # else:\n",
    "#             #     os.rename(filepath,os.path.join(dest2,filename))\n",
    "            \n",
    "#             # duration = waveform.shape[1] / sample_rate\n",
    "#             # rms_energy = np.sqrt(np.mean(samples**2))\n",
    "#             # zcr = librosa.feature.zero_crossing_rate(samples)[0].mean()\n",
    "#             # spectral_centroid = librosa.feature.spectral_centroid(y=samples, sr=sample_rate)[0].mean()\n",
    "#             # spectral_bandwidth = librosa.feature.spectral_bandwidth(y=samples, sr=sample_rate)[0].mean()\n",
    "#             # mfccs = librosa.feature.mfcc(y=samples, sr=sample_rate, n_mfcc=13).mean(axis=1)\n",
    "            \n",
    "#             # frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "#             # mean_spectrogram = np.mean(spectrogram)\n",
    "#             # std_spectrogram = np.std(spectrogram)\n",
    "            \n",
    "#             # dominant_freq = frequencies[np.argmax(spectrogram, axis=0)].mean()\n",
    "    \n",
    "#             # data.append({\n",
    "#             #     'filename': filename,\n",
    "#             #     'speaker_id': speaker_id,\n",
    "#             #     'script_id': script_id,\n",
    "#             #     'audio_type': audio_type,\n",
    "#             #     'duration': duration,\n",
    "#             #     'sample_rate': sample_rate,\n",
    "#             #     'rms_energy': rms_energy,\n",
    "#             #     'zero_crossing_rate': zcr,\n",
    "#             #     'spectral_centroid': spectral_centroid,\n",
    "#             #     'spectral_bandwidth': spectral_bandwidth,\n",
    "#             #     'mfccs': mfccs.tolist(),\n",
    "#             #     'mean_spectrogram': mean_spectrogram,\n",
    "#             #     'std_spectrogram': std_spectrogram,\n",
    "#             #     'dominant_freq': dominant_freq\n",
    "#             # })\n",
    "#             #print(data)\n",
    "\n",
    "#             # plot_waveform(waveformt, sr)\n",
    "#             # plt.show()\n",
    "#             # plot_specgram(waveformt, sr)\n",
    "#             # plt.show()\n",
    "            \n",
    "#         except ValueError as e:\n",
    "#             print(f\"Error reading {filename}: {e}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"An unexpected error occurred with {filename}: {e}\")\n",
    "\n",
    "# #df = pd.DataFrame(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5c236b-a403-4ad1-b6ae-9e342126fbf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m5', 'script2', 'clean']\n",
      "['m7', 'script3', 'clean']\n",
      "['f3', 'script2', 'clean']\n",
      "['m4', 'script4', 'clean']\n",
      "['f2', 'script4', 'clean']\n",
      "['f4', 'script3', 'clean']\n",
      "['m2', 'script3', 'clean']\n",
      "['f6', 'script2', 'clean']\n",
      "['f5', 'script5', 'clean']\n",
      "['m1', 'script4', 'clean']\n",
      "['m4', 'script2', 'clean']\n",
      "['m10', 'script1', 'clean']\n",
      "['f2', 'script2', 'clean']\n",
      "['m5', 'script4', 'clean']\n",
      "['m9', 'script1', 'clean']\n",
      "['m7', 'script5', 'clean']\n",
      "['f3', 'script4', 'clean']\n",
      "['f5', 'script3', 'clean']\n",
      "['m1', 'script2', 'clean']\n",
      "['f4', 'script5', 'clean']\n",
      "['m2', 'script5', 'clean']\n",
      "['f6', 'script4', 'clean']\n",
      "['m7', 'script2', 'clean']\n",
      "['f3', 'script3', 'clean']\n",
      "['m5', 'script3', 'clean']\n",
      "['f2', 'script5', 'clean']\n",
      "['m4', 'script5', 'clean']\n",
      "['m2', 'script2', 'clean']\n",
      "['f6', 'script3', 'clean']\n",
      "['f4', 'script2', 'clean']\n",
      "['f5', 'script4', 'clean']\n",
      "['f9', 'script1', 'clean']\n",
      "['m1', 'script5', 'clean']\n",
      "['f2', 'script3', 'clean']\n",
      "['m4', 'script3', 'clean']\n",
      "['m7', 'script4', 'clean']\n",
      "['f3', 'script5', 'clean']\n",
      "['m5', 'script5', 'clean']\n",
      "['f5', 'script2', 'clean']\n",
      "['m1', 'script3', 'clean']\n",
      "['m2', 'script4', 'clean']\n",
      "['f6', 'script5', 'clean']\n",
      "['f4', 'script4', 'clean']\n",
      "['m10', 'script5', 'clean']\n",
      "['m9', 'script5', 'clean']\n",
      "['m7', 'script1', 'clean']\n",
      "['f9', 'script2', 'clean']\n",
      "['f4', 'script1', 'clean']\n",
      "['m2', 'script1', 'clean']\n",
      "['m9', 'script3', 'clean']\n",
      "['m10', 'script3', 'clean']\n",
      "['f5', 'script1', 'clean']\n",
      "['f9', 'script4', 'clean']\n",
      "['m10', 'script4', 'clean']\n",
      "['f3', 'script1', 'clean']\n",
      "['m5', 'script1', 'clean']\n",
      "['m9', 'script4', 'clean']\n",
      "['f9', 'script3', 'clean']\n",
      "['f6', 'script1', 'clean']\n",
      "['m9', 'script2', 'clean']\n",
      "['m10', 'script2', 'clean']\n",
      "['f2', 'script1', 'clean']\n",
      "['m4', 'script1', 'clean']\n",
      "['m1', 'script1', 'clean']\n",
      "['f9', 'script5', 'clean']\n",
      "['m2', 'script5', 'cleanraw']\n",
      "['m2', 'script2', 'cleanraw']\n",
      "['f5', 'script2', 'cleanraw']\n",
      "['f5', 'script5', 'cleanraw']\n",
      "['m7', 'script2', 'cleanraw']\n",
      "['m7', 'script5', 'cleanraw']\n",
      "['f5', 'script4', 'cleanraw']\n",
      "['f9', 'script1', 'cleanraw']\n",
      "['f5', 'script3', 'cleanraw']\n",
      "['m7', 'script4', 'cleanraw']\n",
      "['m7', 'script3', 'cleanraw']\n",
      "['m2', 'script3', 'cleanraw']\n",
      "['m2', 'script4', 'cleanraw']\n",
      "['m1', 'script1', 'cleanraw']\n",
      "['f3', 'script1', 'cleanraw']\n",
      "['m4', 'script1', 'cleanraw']\n",
      "['f6', 'script1', 'cleanraw']\n",
      "['m9', 'script5', 'cleanraw']\n",
      "['m9', 'script2', 'cleanraw']\n",
      "['m10', 'script1', 'cleanraw']\n",
      "['f4', 'script5', 'cleanraw']\n",
      "['f4', 'script2', 'cleanraw']\n",
      "['f2', 'script1', 'cleanraw']\n",
      "['m9', 'script3', 'cleanraw']\n",
      "['m9', 'script4', 'cleanraw']\n",
      "['m5', 'script1', 'cleanraw']\n",
      "['f4', 'script3', 'cleanraw']\n",
      "['f4', 'script4', 'cleanraw']\n",
      "['m10', 'script5', 'cleanraw']\n",
      "['m10', 'script2', 'cleanraw']\n",
      "['f2', 'script4', 'cleanraw']\n",
      "['f2', 'script3', 'cleanraw']\n",
      "['m5', 'script3', 'cleanraw']\n",
      "['m9', 'script1', 'cleanraw']\n",
      "['m5', 'script4', 'cleanraw']\n",
      "['f4', 'script1', 'cleanraw']\n",
      "['m5', 'script5', 'cleanraw']\n",
      "['m5', 'script2', 'cleanraw']\n",
      "['m10', 'script3', 'cleanraw']\n",
      "['m10', 'script4', 'cleanraw']\n",
      "['f2', 'script2', 'cleanraw']\n",
      "['f2', 'script5', 'cleanraw']\n",
      "['m7', 'script1', 'cleanraw']\n",
      "['f5', 'script1', 'cleanraw']\n",
      "['f9', 'script4', 'cleanraw']\n",
      "['f9', 'script3', 'cleanraw']\n",
      "['m2', 'script1', 'cleanraw']\n",
      "['f3', 'script3', 'cleanraw']\n",
      "['f3', 'script4', 'cleanraw']\n",
      "['m1', 'script3', 'cleanraw']\n",
      "['m1', 'script4', 'cleanraw']\n",
      "['f6', 'script4', 'cleanraw']\n",
      "['f6', 'script3', 'cleanraw']\n",
      "['m4', 'script4', 'cleanraw']\n",
      "['m4', 'script3', 'cleanraw']\n",
      "['f9', 'script2', 'cleanraw']\n",
      "['f9', 'script5', 'cleanraw']\n",
      "['f6', 'script2', 'cleanraw']\n",
      "['f6', 'script5', 'cleanraw']\n",
      "['m4', 'script2', 'cleanraw']\n",
      "['m4', 'script5', 'cleanraw']\n",
      "['f3', 'script5', 'cleanraw']\n",
      "['f3', 'script2', 'cleanraw']\n",
      "['m1', 'script5', 'cleanraw']\n",
      "['m1', 'script2', 'cleanraw']\n",
      "['f2', 'script2', 'ipad', 'balcony1']\n",
      "['m5', 'script2', 'ipad', 'balcony1']\n",
      "['m7', 'script5', 'ipad', 'balcony1']\n",
      "['f5', 'script3', 'ipad', 'balcony1']\n",
      "['m2', 'script3', 'ipad', 'balcony1']\n",
      "['m7', 'script1', 'ipad', 'balcony1']\n",
      "['m5', 'script3', 'ipad', 'balcony1']\n",
      "['f2', 'script3', 'ipad', 'balcony1']\n",
      "['m7', 'script4', 'ipad', 'balcony1']\n",
      "['m2', 'script2', 'ipad', 'balcony1']\n",
      "['f5', 'script2', 'ipad', 'balcony1']\n",
      "['m7', 'script2', 'ipad', 'balcony1']\n",
      "['m2', 'script4', 'ipad', 'balcony1']\n",
      "['f5', 'script4', 'ipad', 'balcony1']\n",
      "['m5', 'script5', 'ipad', 'balcony1']\n",
      "['f2', 'script5', 'ipad', 'balcony1']\n",
      "['m2', 'script1', 'ipad', 'balcony1']\n",
      "['f5', 'script1', 'ipad', 'balcony1']\n",
      "['m7', 'script3', 'ipad', 'balcony1']\n",
      "['f2', 'script1', 'ipad', 'balcony1']\n",
      "['m5', 'script1', 'ipad', 'balcony1']\n",
      "['f5', 'script5', 'ipad', 'balcony1']\n",
      "['m2', 'script5', 'ipad', 'balcony1']\n",
      "['f2', 'script4', 'ipad', 'balcony1']\n",
      "['m5', 'script4', 'ipad', 'balcony1']\n",
      "['m1', 'script2', 'ipad', 'balcony1']\n",
      "['f6', 'script2', 'ipad', 'balcony1']\n",
      "['f3', 'script4', 'ipad', 'balcony1']\n",
      "['m4', 'script4', 'ipad', 'balcony1']\n",
      "['m9', 'script2', 'ipad', 'balcony1']\n",
      "['f9', 'script3', 'ipad', 'balcony1']\n",
      "['f4', 'script5', 'ipad', 'balcony1']\n",
      "['m10', 'script2', 'ipad', 'balcony1']\n",
      "['f3', 'script1', 'ipad', 'balcony1']\n",
      "['m4', 'script1', 'ipad', 'balcony1']\n",
      "['f4', 'script1', 'ipad', 'balcony1']\n",
      "['f6', 'script3', 'ipad', 'balcony1']\n",
      "['m1', 'script3', 'ipad', 'balcony1']\n",
      "['m4', 'script5', 'ipad', 'balcony1']\n",
      "['f3', 'script5', 'ipad', 'balcony1']\n",
      "['m9', 'script3', 'ipad', 'balcony1']\n",
      "['f9', 'script2', 'ipad', 'balcony1']\n",
      "['f4', 'script4', 'ipad', 'balcony1']\n",
      "['m10', 'script3', 'ipad', 'balcony1']\n",
      "['f9', 'script4', 'ipad', 'balcony1']\n",
      "['f4', 'script2', 'ipad', 'balcony1']\n",
      "['m10', 'script5', 'ipad', 'balcony1']\n",
      "['f9', 'script1', 'ipad', 'balcony1']\n",
      "['f6', 'script5', 'ipad', 'balcony1']\n",
      "['m1', 'script5', 'ipad', 'balcony1']\n",
      "['m4', 'script3', 'ipad', 'balcony1']\n",
      "['f3', 'script3', 'ipad', 'balcony1']\n",
      "['m9', 'script5', 'ipad', 'balcony1']\n",
      "['f9', 'script5', 'ipad', 'balcony1']\n",
      "['f4', 'script3', 'ipad', 'balcony1']\n",
      "['m1', 'script1', 'ipad', 'balcony1']\n",
      "['f6', 'script1', 'ipad', 'balcony1']\n",
      "['m10', 'script4', 'ipad', 'balcony1']\n",
      "['m9', 'script1', 'ipad', 'balcony1']\n",
      "['m1', 'script4', 'ipad', 'balcony1']\n",
      "['f6', 'script4', 'ipad', 'balcony1']\n",
      "['m10', 'script1', 'ipad', 'balcony1']\n",
      "['f3', 'script2', 'ipad', 'balcony1']\n",
      "['m4', 'script2', 'ipad', 'balcony1']\n",
      "['m9', 'script4', 'ipad', 'balcony1']\n",
      "['m9', 'script3', 'ipad', 'bedroom1']\n",
      "['f3', 'script5', 'ipad', 'bedroom1']\n",
      "['m4', 'script5', 'ipad', 'bedroom1']\n",
      "['m1', 'script3', 'ipad', 'bedroom1']\n",
      "['f6', 'script3', 'ipad', 'bedroom1']\n",
      "['f4', 'script1', 'ipad', 'bedroom1']\n",
      "['m10', 'script3', 'ipad', 'bedroom1']\n",
      "['f4', 'script4', 'ipad', 'bedroom1']\n",
      "['f9', 'script2', 'ipad', 'bedroom1']\n",
      "['m9', 'script2', 'ipad', 'bedroom1']\n",
      "['m4', 'script4', 'ipad', 'bedroom1']\n",
      "['f3', 'script4', 'ipad', 'bedroom1']\n",
      "['f6', 'script2', 'ipad', 'bedroom1']\n",
      "['m1', 'script2', 'ipad', 'bedroom1']\n",
      "['m4', 'script1', 'ipad', 'bedroom1']\n",
      "['f3', 'script1', 'ipad', 'bedroom1']\n",
      "['m10', 'script2', 'ipad', 'bedroom1']\n",
      "['f4', 'script5', 'ipad', 'bedroom1']\n",
      "['f9', 'script3', 'ipad', 'bedroom1']\n",
      "['m9', 'script1', 'ipad', 'bedroom1']\n",
      "['m10', 'script4', 'ipad', 'bedroom1']\n",
      "['f6', 'script1', 'ipad', 'bedroom1']\n",
      "['m1', 'script1', 'ipad', 'bedroom1']\n",
      "['f4', 'script3', 'ipad', 'bedroom1']\n",
      "['f9', 'script5', 'ipad', 'bedroom1']\n",
      "['m9', 'script4', 'ipad', 'bedroom1']\n",
      "['m4', 'script2', 'ipad', 'bedroom1']\n",
      "['f3', 'script2', 'ipad', 'bedroom1']\n",
      "['m10', 'script1', 'ipad', 'bedroom1']\n",
      "['f6', 'script4', 'ipad', 'bedroom1']\n",
      "['m1', 'script4', 'ipad', 'bedroom1']\n",
      "['m10', 'script5', 'ipad', 'bedroom1']\n",
      "['f4', 'script2', 'ipad', 'bedroom1']\n",
      "['f9', 'script4', 'ipad', 'bedroom1']\n",
      "['m9', 'script5', 'ipad', 'bedroom1']\n",
      "['f3', 'script3', 'ipad', 'bedroom1']\n",
      "['m4', 'script3', 'ipad', 'bedroom1']\n",
      "['m1', 'script5', 'ipad', 'bedroom1']\n",
      "['f6', 'script5', 'ipad', 'bedroom1']\n",
      "['f9', 'script1', 'ipad', 'bedroom1']\n",
      "['f2', 'script3', 'ipad', 'bedroom1']\n",
      "['m5', 'script3', 'ipad', 'bedroom1']\n",
      "['m7', 'script1', 'ipad', 'bedroom1']\n",
      "['f5', 'script2', 'ipad', 'bedroom1']\n",
      "['m2', 'script2', 'ipad', 'bedroom1']\n",
      "['m7', 'script4', 'ipad', 'bedroom1']\n",
      "['m5', 'script2', 'ipad', 'bedroom1']\n",
      "['f2', 'script2', 'ipad', 'bedroom1']\n",
      "['m2', 'script3', 'ipad', 'bedroom1']\n",
      "['f5', 'script3', 'ipad', 'bedroom1']\n",
      "['m7', 'script5', 'ipad', 'bedroom1']\n",
      "['m2', 'script5', 'ipad', 'bedroom1']\n",
      "['f5', 'script5', 'ipad', 'bedroom1']\n",
      "['m5', 'script1', 'ipad', 'bedroom1']\n",
      "['f2', 'script1', 'ipad', 'bedroom1']\n",
      "['m7', 'script3', 'ipad', 'bedroom1']\n",
      "['m5', 'script4', 'ipad', 'bedroom1']\n",
      "['f2', 'script4', 'ipad', 'bedroom1']\n",
      "['f5', 'script4', 'ipad', 'bedroom1']\n",
      "['m2', 'script4', 'ipad', 'bedroom1']\n",
      "['m7', 'script2', 'ipad', 'bedroom1']\n",
      "['f5', 'script1', 'ipad', 'bedroom1']\n",
      "['m2', 'script1', 'ipad', 'bedroom1']\n",
      "['f2', 'script5', 'ipad', 'bedroom1']\n",
      "['m5', 'script5', 'ipad', 'bedroom1']\n",
      "['f9', 'script5', 'ipad', 'confroom1']\n",
      "['f5', 'script5', 'ipad', 'confroom1']\n",
      "['m1', 'script4', 'ipad', 'confroom1']\n",
      "['f6', 'script1', 'ipad', 'confroom1']\n",
      "['m9', 'script3', 'ipad', 'confroom1']\n",
      "['m5', 'script3', 'ipad', 'confroom1']\n",
      "['m7', 'script1', 'ipad', 'confroom1']\n",
      "['f4', 'script3', 'ipad', 'confroom1']\n",
      "['m10', 'script5', 'ipad', 'confroom1']\n",
      "['m4', 'script5', 'ipad', 'confroom1']\n",
      "['m7', 'script2', 'ipad', 'confroom1']\n",
      "['f3', 'script3', 'ipad', 'confroom1']\n",
      "['f6', 'script2', 'ipad', 'confroom1']\n",
      "['m2', 'script3', 'ipad', 'confroom1']\n",
      "['f2', 'script5', 'ipad', 'confroom1']\n",
      "['m2', 'script5', 'ipad', 'confroom1']\n",
      "['f6', 'script4', 'ipad', 'confroom1']\n",
      "['m1', 'script1', 'ipad', 'confroom1']\n",
      "['f2', 'script3', 'ipad', 'confroom1']\n",
      "['f3', 'script5', 'ipad', 'confroom1']\n",
      "['m7', 'script4', 'ipad', 'confroom1']\n",
      "['m10', 'script3', 'ipad', 'confroom1']\n",
      "['f4', 'script5', 'ipad', 'confroom1']\n",
      "['m4', 'script3', 'ipad', 'confroom1']\n",
      "['m1', 'script2', 'ipad', 'confroom1']\n",
      "['f9', 'script3', 'ipad', 'confroom1']\n",
      "['f5', 'script3', 'ipad', 'confroom1']\n",
      "['m9', 'script5', 'ipad', 'confroom1']\n",
      "['m5', 'script5', 'ipad', 'confroom1']\n",
      "['m4', 'script2', 'ipad', 'confroom1']\n",
      "['m10', 'script2', 'ipad', 'confroom1']\n",
      "['f4', 'script4', 'ipad', 'confroom1']\n",
      "['m9', 'script4', 'ipad', 'confroom1']\n",
      "['m5', 'script4', 'ipad', 'confroom1']\n",
      "['f2', 'script1', 'ipad', 'confroom1']\n",
      "['m1', 'script3', 'ipad', 'confroom1']\n",
      "['f9', 'script2', 'ipad', 'confroom1']\n",
      "['f5', 'script2', 'ipad', 'confroom1']\n",
      "['f2', 'script2', 'ipad', 'confroom1']\n",
      "['f5', 'script1', 'ipad', 'confroom1']\n",
      "['f9', 'script1', 'ipad', 'confroom1']\n",
      "['m2', 'script4', 'ipad', 'confroom1']\n",
      "['f6', 'script5', 'ipad', 'confroom1']\n",
      "['m10', 'script1', 'ipad', 'confroom1']\n",
      "['f3', 'script4', 'ipad', 'confroom1']\n",
      "['m7', 'script5', 'ipad', 'confroom1']\n",
      "['m4', 'script1', 'ipad', 'confroom1']\n",
      "['f4', 'script1', 'ipad', 'confroom1']\n",
      "['m7', 'script3', 'ipad', 'confroom1']\n",
      "['f3', 'script2', 'ipad', 'confroom1']\n",
      "['f2', 'script4', 'ipad', 'confroom1']\n",
      "['m5', 'script1', 'ipad', 'confroom1']\n",
      "['m9', 'script1', 'ipad', 'confroom1']\n",
      "['f6', 'script3', 'ipad', 'confroom1']\n",
      "['m2', 'script2', 'ipad', 'confroom1']\n",
      "['m9', 'script2', 'ipad', 'confroom1']\n",
      "['m5', 'script2', 'ipad', 'confroom1']\n",
      "['m2', 'script1', 'ipad', 'confroom1']\n",
      "['f9', 'script4', 'ipad', 'confroom1']\n",
      "['f5', 'script4', 'ipad', 'confroom1']\n",
      "['m1', 'script5', 'ipad', 'confroom1']\n",
      "['m4', 'script4', 'ipad', 'confroom1']\n",
      "['f4', 'script2', 'ipad', 'confroom1']\n",
      "['f3', 'script1', 'ipad', 'confroom1']\n",
      "['m10', 'script4', 'ipad', 'confroom1']\n",
      "['m7', 'script1', 'ipad', 'confroom2']\n",
      "['f4', 'script3', 'ipad', 'confroom2']\n",
      "['m10', 'script5', 'ipad', 'confroom2']\n",
      "['m4', 'script5', 'ipad', 'confroom2']\n",
      "['f9', 'script5', 'ipad', 'confroom2']\n",
      "['f5', 'script5', 'ipad', 'confroom2']\n",
      "['m1', 'script4', 'ipad', 'confroom2']\n",
      "['m9', 'script3', 'ipad', 'confroom2']\n",
      "['f6', 'script1', 'ipad', 'confroom2']\n",
      "['m5', 'script3', 'ipad', 'confroom2']\n",
      "['f6', 'script2', 'ipad', 'confroom2']\n",
      "['m2', 'script3', 'ipad', 'confroom2']\n",
      "['f2', 'script5', 'ipad', 'confroom2']\n",
      "['m7', 'script2', 'ipad', 'confroom2']\n",
      "['f3', 'script3', 'ipad', 'confroom2']\n",
      "['f3', 'script5', 'ipad', 'confroom2']\n",
      "['m7', 'script4', 'ipad', 'confroom2']\n",
      "['m2', 'script5', 'ipad', 'confroom2']\n",
      "['f6', 'script4', 'ipad', 'confroom2']\n",
      "['m1', 'script1', 'ipad', 'confroom2']\n",
      "['f2', 'script3', 'ipad', 'confroom2']\n",
      "['m1', 'script2', 'ipad', 'confroom2']\n",
      "['f9', 'script3', 'ipad', 'confroom2']\n",
      "['f5', 'script3', 'ipad', 'confroom2']\n",
      "['m9', 'script5', 'ipad', 'confroom2']\n",
      "['m5', 'script5', 'ipad', 'confroom2']\n",
      "['m10', 'script3', 'ipad', 'confroom2']\n",
      "['f4', 'script5', 'ipad', 'confroom2']\n",
      "['m4', 'script3', 'ipad', 'confroom2']\n",
      "['m9', 'script4', 'ipad', 'confroom2']\n",
      "['m5', 'script4', 'ipad', 'confroom2']\n",
      "['f2', 'script1', 'ipad', 'confroom2']\n",
      "['m1', 'script3', 'ipad', 'confroom2']\n",
      "['f9', 'script2', 'ipad', 'confroom2']\n",
      "['f5', 'script2', 'ipad', 'confroom2']\n",
      "['m4', 'script2', 'ipad', 'confroom2']\n",
      "['m10', 'script2', 'ipad', 'confroom2']\n",
      "['f4', 'script4', 'ipad', 'confroom2']\n",
      "['m10', 'script1', 'ipad', 'confroom2']\n",
      "['f3', 'script4', 'ipad', 'confroom2']\n",
      "['m7', 'script5', 'ipad', 'confroom2']\n",
      "['m4', 'script1', 'ipad', 'confroom2']\n",
      "['f2', 'script2', 'ipad', 'confroom2']\n",
      "['f5', 'script1', 'ipad', 'confroom2']\n",
      "['f9', 'script1', 'ipad', 'confroom2']\n",
      "['m2', 'script4', 'ipad', 'confroom2']\n",
      "['f6', 'script5', 'ipad', 'confroom2']\n",
      "['f2', 'script4', 'ipad', 'confroom2']\n",
      "['m5', 'script1', 'ipad', 'confroom2']\n",
      "['f6', 'script3', 'ipad', 'confroom2']\n",
      "['m9', 'script1', 'ipad', 'confroom2']\n",
      "['m2', 'script2', 'ipad', 'confroom2']\n",
      "['f4', 'script1', 'ipad', 'confroom2']\n",
      "['m7', 'script3', 'ipad', 'confroom2']\n",
      "['f3', 'script2', 'ipad', 'confroom2']\n",
      "['m4', 'script4', 'ipad', 'confroom2']\n",
      "['f4', 'script2', 'ipad', 'confroom2']\n",
      "['f3', 'script1', 'ipad', 'confroom2']\n",
      "['m10', 'script4', 'ipad', 'confroom2']\n",
      "['m9', 'script2', 'ipad', 'confroom2']\n",
      "['m5', 'script2', 'ipad', 'confroom2']\n",
      "['m2', 'script1', 'ipad', 'confroom2']\n",
      "['f9', 'script4', 'ipad', 'confroom2']\n",
      "['f5', 'script4', 'ipad', 'confroom2']\n",
      "['m1', 'script5', 'ipad', 'confroom2']\n",
      "['f3', 'script1', 'ipad', 'livingroom1']\n",
      "['f6', 'script5', 'ipad', 'livingroom1']\n",
      "['m1', 'script4', 'ipad', 'livingroom1']\n",
      "['f3', 'script4', 'ipad', 'livingroom1']\n",
      "['m4', 'script5', 'ipad', 'livingroom1']\n",
      "['m1', 'script1', 'ipad', 'livingroom1']\n",
      "['m5', 'script3', 'ipad', 'livingroom1']\n",
      "['f2', 'script2', 'ipad', 'livingroom1']\n",
      "['f9', 'script3', 'ipad', 'livingroom1']\n",
      "['f4', 'script3', 'ipad', 'livingroom1']\n",
      "['m2', 'script4', 'ipad', 'livingroom1']\n",
      "['f5', 'script5', 'ipad', 'livingroom1']\n",
      "['m10', 'script4', 'ipad', 'livingroom1']\n",
      "['m2', 'script1', 'ipad', 'livingroom1']\n",
      "['m7', 'script5', 'ipad', 'livingroom1']\n",
      "['m9', 'script5', 'ipad', 'livingroom1']\n",
      "['m10', 'script1', 'ipad', 'livingroom1']\n",
      "['f2', 'script3', 'ipad', 'livingroom1']\n",
      "['m5', 'script2', 'ipad', 'livingroom1']\n",
      "['f9', 'script2', 'ipad', 'livingroom1']\n",
      "['m1', 'script5', 'ipad', 'livingroom1']\n",
      "['f6', 'script4', 'ipad', 'livingroom1']\n",
      "['m4', 'script1', 'ipad', 'livingroom1']\n",
      "['f6', 'script1', 'ipad', 'livingroom1']\n",
      "['m4', 'script4', 'ipad', 'livingroom1']\n",
      "['f3', 'script5', 'ipad', 'livingroom1']\n",
      "['m7', 'script1', 'ipad', 'livingroom1']\n",
      "['m9', 'script1', 'ipad', 'livingroom1']\n",
      "['m10', 'script5', 'ipad', 'livingroom1']\n",
      "['f5', 'script4', 'ipad', 'livingroom1']\n",
      "['m2', 'script5', 'ipad', 'livingroom1']\n",
      "['m9', 'script4', 'ipad', 'livingroom1']\n",
      "['m7', 'script4', 'ipad', 'livingroom1']\n",
      "['f5', 'script1', 'ipad', 'livingroom1']\n",
      "['f4', 'script2', 'ipad', 'livingroom1']\n",
      "['f4', 'script1', 'ipad', 'livingroom1']\n",
      "['f4', 'script4', 'ipad', 'livingroom1']\n",
      "['m10', 'script3', 'ipad', 'livingroom1']\n",
      "['m2', 'script3', 'ipad', 'livingroom1']\n",
      "['f5', 'script2', 'ipad', 'livingroom1']\n",
      "['m9', 'script2', 'ipad', 'livingroom1']\n",
      "['m7', 'script2', 'ipad', 'livingroom1']\n",
      "['f6', 'script2', 'ipad', 'livingroom1']\n",
      "['m1', 'script3', 'ipad', 'livingroom1']\n",
      "['f3', 'script3', 'ipad', 'livingroom1']\n",
      "['m4', 'script2', 'ipad', 'livingroom1']\n",
      "['m5', 'script4', 'ipad', 'livingroom1']\n",
      "['f2', 'script5', 'ipad', 'livingroom1']\n",
      "['f9', 'script1', 'ipad', 'livingroom1']\n",
      "['m5', 'script1', 'ipad', 'livingroom1']\n",
      "['f9', 'script4', 'ipad', 'livingroom1']\n",
      "['f5', 'script3', 'ipad', 'livingroom1']\n",
      "['m2', 'script2', 'ipad', 'livingroom1']\n",
      "['m10', 'script2', 'ipad', 'livingroom1']\n",
      "['m7', 'script3', 'ipad', 'livingroom1']\n",
      "['m9', 'script3', 'ipad', 'livingroom1']\n",
      "['f4', 'script5', 'ipad', 'livingroom1']\n",
      "['f2', 'script4', 'ipad', 'livingroom1']\n",
      "['m5', 'script5', 'ipad', 'livingroom1']\n",
      "['f9', 'script5', 'ipad', 'livingroom1']\n",
      "['f2', 'script1', 'ipad', 'livingroom1']\n",
      "['m1', 'script2', 'ipad', 'livingroom1']\n",
      "['f6', 'script3', 'ipad', 'livingroom1']\n",
      "['m4', 'script3', 'ipad', 'livingroom1']\n",
      "['f3', 'script2', 'ipad', 'livingroom1']\n",
      "['f5', 'script3', 'ipad', 'office1']\n",
      "['m9', 'script5', 'ipad', 'office1']\n",
      "['m2', 'script3', 'ipad', 'office1']\n",
      "['m10', 'script2', 'ipad', 'office1']\n",
      "['m5', 'script5', 'ipad', 'office1']\n",
      "['f6', 'script5', 'ipad', 'office1']\n",
      "['m1', 'script5', 'ipad', 'office1']\n",
      "['f2', 'script5', 'ipad', 'office1']\n",
      "['f9', 'script3', 'ipad', 'office1']\n",
      "['f2', 'script1', 'ipad', 'office1']\n",
      "['m1', 'script1', 'ipad', 'office1']\n",
      "['m7', 'script2', 'ipad', 'office1']\n",
      "['f4', 'script2', 'ipad', 'office1']\n",
      "['f6', 'script1', 'ipad', 'office1']\n",
      "['m5', 'script1', 'ipad', 'office1']\n",
      "['m9', 'script1', 'ipad', 'office1']\n",
      "['m4', 'script4', 'ipad', 'office1']\n",
      "['f3', 'script4', 'ipad', 'office1']\n",
      "['m10', 'script3', 'ipad', 'office1']\n",
      "['m2', 'script2', 'ipad', 'office1']\n",
      "['m4', 'script1', 'ipad', 'office1']\n",
      "['m9', 'script4', 'ipad', 'office1']\n",
      "['f5', 'script2', 'ipad', 'office1']\n",
      "['f3', 'script1', 'ipad', 'office1']\n",
      "['f9', 'script2', 'ipad', 'office1']\n",
      "['f2', 'script4', 'ipad', 'office1']\n",
      "['m1', 'script4', 'ipad', 'office1']\n",
      "['f6', 'script4', 'ipad', 'office1']\n",
      "['m5', 'script4', 'ipad', 'office1']\n",
      "['f4', 'script3', 'ipad', 'office1']\n",
      "['m7', 'script3', 'ipad', 'office1']\n",
      "['f3', 'script5', 'ipad', 'office1']\n",
      "['m4', 'script5', 'ipad', 'office1']\n",
      "['f9', 'script1', 'ipad', 'office1']\n",
      "['f4', 'script4', 'ipad', 'office1']\n",
      "['m7', 'script4', 'ipad', 'office1']\n",
      "['m2', 'script1', 'ipad', 'office1']\n",
      "['m4', 'script2', 'ipad', 'office1']\n",
      "['f5', 'script1', 'ipad', 'office1']\n",
      "['f3', 'script2', 'ipad', 'office1']\n",
      "['f5', 'script5', 'ipad', 'office1']\n",
      "['m10', 'script4', 'ipad', 'office1']\n",
      "['m2', 'script5', 'ipad', 'office1']\n",
      "['m9', 'script3', 'ipad', 'office1']\n",
      "['f6', 'script3', 'ipad', 'office1']\n",
      "['m5', 'script3', 'ipad', 'office1']\n",
      "['f9', 'script5', 'ipad', 'office1']\n",
      "['f2', 'script3', 'ipad', 'office1']\n",
      "['m1', 'script3', 'ipad', 'office1']\n",
      "['m7', 'script5', 'ipad', 'office1']\n",
      "['f4', 'script5', 'ipad', 'office1']\n",
      "['f3', 'script3', 'ipad', 'office1']\n",
      "['m4', 'script3', 'ipad', 'office1']\n",
      "['m10', 'script1', 'ipad', 'office1']\n",
      "['m9', 'script2', 'ipad', 'office1']\n",
      "['m2', 'script4', 'ipad', 'office1']\n",
      "['m10', 'script5', 'ipad', 'office1']\n",
      "['f5', 'script4', 'ipad', 'office1']\n",
      "['m1', 'script2', 'ipad', 'office1']\n",
      "['f2', 'script2', 'ipad', 'office1']\n",
      "['f4', 'script1', 'ipad', 'office1']\n",
      "['f9', 'script4', 'ipad', 'office1']\n",
      "['m7', 'script1', 'ipad', 'office1']\n",
      "['m5', 'script2', 'ipad', 'office1']\n",
      "['f6', 'script2', 'ipad', 'office1']\n",
      "['m5', 'script5', 'ipad', 'office2']\n",
      "['f6', 'script5', 'ipad', 'office2']\n",
      "['m1', 'script5', 'ipad', 'office2']\n",
      "['f2', 'script5', 'ipad', 'office2']\n",
      "['f9', 'script3', 'ipad', 'office2']\n",
      "['f5', 'script3', 'ipad', 'office2']\n",
      "['m9', 'script5', 'ipad', 'office2']\n",
      "['m2', 'script3', 'ipad', 'office2']\n",
      "['m10', 'script2', 'ipad', 'office2']\n",
      "['m9', 'script1', 'ipad', 'office2']\n",
      "['m4', 'script4', 'ipad', 'office2']\n",
      "['f3', 'script4', 'ipad', 'office2']\n",
      "['f2', 'script1', 'ipad', 'office2']\n",
      "['m1', 'script1', 'ipad', 'office2']\n",
      "['m7', 'script2', 'ipad', 'office2']\n",
      "['f4', 'script2', 'ipad', 'office2']\n",
      "['f6', 'script1', 'ipad', 'office2']\n",
      "['m5', 'script1', 'ipad', 'office2']\n",
      "['f9', 'script2', 'ipad', 'office2']\n",
      "['f2', 'script4', 'ipad', 'office2']\n",
      "['m1', 'script4', 'ipad', 'office2']\n",
      "['f6', 'script4', 'ipad', 'office2']\n",
      "['m5', 'script4', 'ipad', 'office2']\n",
      "['m10', 'script3', 'ipad', 'office2']\n",
      "['m2', 'script2', 'ipad', 'office2']\n",
      "['m4', 'script1', 'ipad', 'office2']\n",
      "['m9', 'script4', 'ipad', 'office2']\n",
      "['f5', 'script2', 'ipad', 'office2']\n",
      "['f3', 'script1', 'ipad', 'office2']\n",
      "['f3', 'script5', 'ipad', 'office2']\n",
      "['m4', 'script5', 'ipad', 'office2']\n",
      "['f4', 'script3', 'ipad', 'office2']\n",
      "['m7', 'script3', 'ipad', 'office2']\n",
      "['m2', 'script1', 'ipad', 'office2']\n",
      "['m4', 'script2', 'ipad', 'office2']\n",
      "['f5', 'script1', 'ipad', 'office2']\n",
      "['f3', 'script2', 'ipad', 'office2']\n",
      "['f9', 'script1', 'ipad', 'office2']\n",
      "['f4', 'script4', 'ipad', 'office2']\n",
      "['m7', 'script4', 'ipad', 'office2']\n",
      "['f6', 'script3', 'ipad', 'office2']\n",
      "['m5', 'script3', 'ipad', 'office2']\n",
      "['f9', 'script5', 'ipad', 'office2']\n",
      "['f2', 'script3', 'ipad', 'office2']\n",
      "['m1', 'script3', 'ipad', 'office2']\n",
      "['f5', 'script5', 'ipad', 'office2']\n",
      "['m10', 'script4', 'ipad', 'office2']\n",
      "['m2', 'script5', 'ipad', 'office2']\n",
      "['m9', 'script3', 'ipad', 'office2']\n",
      "['f3', 'script3', 'ipad', 'office2']\n",
      "['m4', 'script3', 'ipad', 'office2']\n",
      "['m10', 'script1', 'ipad', 'office2']\n",
      "['m7', 'script5', 'ipad', 'office2']\n",
      "['f4', 'script5', 'ipad', 'office2']\n",
      "['m1', 'script2', 'ipad', 'office2']\n",
      "['f2', 'script2', 'ipad', 'office2']\n",
      "['f4', 'script1', 'ipad', 'office2']\n",
      "['f9', 'script4', 'ipad', 'office2']\n",
      "['m7', 'script1', 'ipad', 'office2']\n",
      "['m5', 'script2', 'ipad', 'office2']\n",
      "['f6', 'script2', 'ipad', 'office2']\n",
      "['m9', 'script2', 'ipad', 'office2']\n",
      "['m2', 'script4', 'ipad', 'office2']\n",
      "['m10', 'script5', 'ipad', 'office2']\n",
      "['f5', 'script4', 'ipad', 'office2']\n",
      "['m10', 'script2', 'ipadflat', 'confroom1']\n",
      "['m10', 'script5', 'ipadflat', 'confroom1']\n",
      "['m7', 'script3', 'ipadflat', 'confroom1']\n",
      "['f6', 'script3', 'ipadflat', 'confroom1']\n",
      "['m1', 'script3', 'ipadflat', 'confroom1']\n",
      "['m7', 'script4', 'ipadflat', 'confroom1']\n",
      "['f6', 'script4', 'ipadflat', 'confroom1']\n",
      "['m1', 'script4', 'ipadflat', 'confroom1']\n",
      "['m10', 'script1', 'ipadflat', 'confroom1']\n",
      "['m1', 'script5', 'ipadflat', 'confroom1']\n",
      "['f6', 'script5', 'ipadflat', 'confroom1']\n",
      "['m7', 'script5', 'ipadflat', 'confroom1']\n",
      "['m1', 'script2', 'ipadflat', 'confroom1']\n",
      "['f6', 'script2', 'ipadflat', 'confroom1']\n",
      "['m7', 'script2', 'ipadflat', 'confroom1']\n",
      "['f6', 'script1', 'ipadflat', 'confroom1']\n",
      "['m10', 'script4', 'ipadflat', 'confroom1']\n",
      "['m1', 'script1', 'ipadflat', 'confroom1']\n",
      "['m7', 'script1', 'ipadflat', 'confroom1']\n",
      "['m10', 'script3', 'ipadflat', 'confroom1']\n",
      "['f3', 'script2', 'ipadflat', 'confroom1']\n",
      "['m4', 'script2', 'ipadflat', 'confroom1']\n",
      "['f5', 'script2', 'ipadflat', 'confroom1']\n",
      "['f9', 'script5', 'ipadflat', 'confroom1']\n",
      "['m2', 'script2', 'ipadflat', 'confroom1']\n",
      "['f3', 'script5', 'ipadflat', 'confroom1']\n",
      "['m4', 'script5', 'ipadflat', 'confroom1']\n",
      "['f5', 'script5', 'ipadflat', 'confroom1']\n",
      "['f9', 'script2', 'ipadflat', 'confroom1']\n",
      "['m2', 'script5', 'ipadflat', 'confroom1']\n",
      "['m5', 'script4', 'ipadflat', 'confroom1']\n",
      "['m9', 'script3', 'ipadflat', 'confroom1']\n",
      "['f2', 'script4', 'ipadflat', 'confroom1']\n",
      "['f9', 'script1', 'ipadflat', 'confroom1']\n",
      "['f4', 'script4', 'ipadflat', 'confroom1']\n",
      "['m5', 'script3', 'ipadflat', 'confroom1']\n",
      "['m4', 'script1', 'ipadflat', 'confroom1']\n",
      "['m9', 'script4', 'ipadflat', 'confroom1']\n",
      "['f2', 'script3', 'ipadflat', 'confroom1']\n",
      "['f3', 'script1', 'ipadflat', 'confroom1']\n",
      "['m2', 'script1', 'ipadflat', 'confroom1']\n",
      "['f4', 'script3', 'ipadflat', 'confroom1']\n",
      "['f5', 'script1', 'ipadflat', 'confroom1']\n",
      "['f4', 'script2', 'ipadflat', 'confroom1']\n",
      "['f2', 'script2', 'ipadflat', 'confroom1']\n",
      "['m9', 'script5', 'ipadflat', 'confroom1']\n",
      "['m5', 'script2', 'ipadflat', 'confroom1']\n",
      "['f4', 'script5', 'ipadflat', 'confroom1']\n",
      "['f2', 'script5', 'ipadflat', 'confroom1']\n",
      "['m9', 'script2', 'ipadflat', 'confroom1']\n",
      "['m5', 'script5', 'ipadflat', 'confroom1']\n",
      "['m2', 'script4', 'ipadflat', 'confroom1']\n",
      "['f9', 'script3', 'ipadflat', 'confroom1']\n",
      "['f5', 'script4', 'ipadflat', 'confroom1']\n",
      "['m4', 'script4', 'ipadflat', 'confroom1']\n",
      "['f3', 'script4', 'ipadflat', 'confroom1']\n",
      "['m9', 'script1', 'ipadflat', 'confroom1']\n",
      "['m2', 'script3', 'ipadflat', 'confroom1']\n",
      "['f9', 'script4', 'ipadflat', 'confroom1']\n",
      "['f5', 'script3', 'ipadflat', 'confroom1']\n",
      "['f4', 'script1', 'ipadflat', 'confroom1']\n",
      "['m4', 'script3', 'ipadflat', 'confroom1']\n",
      "['m5', 'script1', 'ipadflat', 'confroom1']\n",
      "['f3', 'script3', 'ipadflat', 'confroom1']\n",
      "['f2', 'script1', 'ipadflat', 'confroom1']\n",
      "['f9', 'script1', 'ipadflat', 'office1']\n",
      "['m5', 'script4', 'ipadflat', 'office1']\n",
      "['f2', 'script5', 'ipadflat', 'office1']\n",
      "['f9', 'script4', 'ipadflat', 'office1']\n",
      "['m5', 'script1', 'ipadflat', 'office1']\n",
      "['f6', 'script2', 'ipadflat', 'office1']\n",
      "['m1', 'script3', 'ipadflat', 'office1']\n",
      "['f3', 'script3', 'ipadflat', 'office1']\n",
      "['m4', 'script2', 'ipadflat', 'office1']\n",
      "['m2', 'script3', 'ipadflat', 'office1']\n",
      "['f5', 'script2', 'ipadflat', 'office1']\n",
      "['m10', 'script3', 'ipadflat', 'office1']\n",
      "['m9', 'script2', 'ipadflat', 'office1']\n",
      "['m7', 'script2', 'ipadflat', 'office1']\n",
      "['f4', 'script1', 'ipadflat', 'office1']\n",
      "['f4', 'script4', 'ipadflat', 'office1']\n",
      "['m1', 'script2', 'ipadflat', 'office1']\n",
      "['f6', 'script3', 'ipadflat', 'office1']\n",
      "['m4', 'script3', 'ipadflat', 'office1']\n",
      "['f3', 'script2', 'ipadflat', 'office1']\n",
      "['f2', 'script4', 'ipadflat', 'office1']\n",
      "['m5', 'script5', 'ipadflat', 'office1']\n",
      "['f2', 'script1', 'ipadflat', 'office1']\n",
      "['f9', 'script5', 'ipadflat', 'office1']\n",
      "['f4', 'script5', 'ipadflat', 'office1']\n",
      "['m10', 'script2', 'ipadflat', 'office1']\n",
      "['f5', 'script3', 'ipadflat', 'office1']\n",
      "['m2', 'script2', 'ipadflat', 'office1']\n",
      "['m7', 'script3', 'ipadflat', 'office1']\n",
      "['m9', 'script3', 'ipadflat', 'office1']\n",
      "['m10', 'script4', 'ipadflat', 'office1']\n",
      "['m2', 'script4', 'ipadflat', 'office1']\n",
      "['f5', 'script5', 'ipadflat', 'office1']\n",
      "['m7', 'script5', 'ipadflat', 'office1']\n",
      "['m9', 'script5', 'ipadflat', 'office1']\n",
      "['m10', 'script1', 'ipadflat', 'office1']\n",
      "['m2', 'script1', 'ipadflat', 'office1']\n",
      "['f4', 'script3', 'ipadflat', 'office1']\n",
      "['m5', 'script3', 'ipadflat', 'office1']\n",
      "['f2', 'script2', 'ipadflat', 'office1']\n",
      "['f9', 'script3', 'ipadflat', 'office1']\n",
      "['f6', 'script5', 'ipadflat', 'office1']\n",
      "['m1', 'script4', 'ipadflat', 'office1']\n",
      "['f3', 'script1', 'ipadflat', 'office1']\n",
      "['m1', 'script1', 'ipadflat', 'office1']\n",
      "['f3', 'script4', 'ipadflat', 'office1']\n",
      "['m4', 'script5', 'ipadflat', 'office1']\n",
      "['f4', 'script2', 'ipadflat', 'office1']\n",
      "['f5', 'script4', 'ipadflat', 'office1']\n",
      "['m2', 'script5', 'ipadflat', 'office1']\n",
      "['m7', 'script1', 'ipadflat', 'office1']\n",
      "['m9', 'script1', 'ipadflat', 'office1']\n",
      "['m10', 'script5', 'ipadflat', 'office1']\n",
      "['f5', 'script1', 'ipadflat', 'office1']\n",
      "['m9', 'script4', 'ipadflat', 'office1']\n",
      "['m7', 'script4', 'ipadflat', 'office1']\n",
      "['m4', 'script1', 'ipadflat', 'office1']\n",
      "['m1', 'script5', 'ipadflat', 'office1']\n",
      "['f6', 'script4', 'ipadflat', 'office1']\n",
      "['m4', 'script4', 'ipadflat', 'office1']\n",
      "['f3', 'script5', 'ipadflat', 'office1']\n",
      "['f6', 'script1', 'ipadflat', 'office1']\n",
      "['f2', 'script3', 'ipadflat', 'office1']\n",
      "['m5', 'script2', 'ipadflat', 'office1']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 51\u001b[0m\n\u001b[1;32m     35\u001b[0m             data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     36\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m: filename,\n\u001b[1;32m     37\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker_id\u001b[39m\u001b[38;5;124m'\u001b[39m: speaker_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZCR\u001b[39m\u001b[38;5;124m'\u001b[39m: zcr,\n\u001b[1;32m     48\u001b[0m             })\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m---> 51\u001b[0m metadata_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_metadata_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(metadata_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mcreate_metadata_df\u001b[0;34m(directories)\u001b[0m\n\u001b[1;32m     16\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory,filename)\n\u001b[1;32m     17\u001b[0m y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(filepath,sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m y\u001b[38;5;241m=\u001b[39m\u001b[43mnoisereduce\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# reducing noise, without it almost all audio is considered speech with based top_db being 60\u001b[39;00m\n\u001b[1;32m     19\u001b[0m duration \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mget_duration(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m     20\u001b[0m db \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mamplitude_to_db(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/noisereduce/noisereduce.py:185\u001b[0m, in \u001b[0;36mreduce_noise\u001b[0;34m(y, sr, stationary, y_noise, prop_decrease, time_constant_s, freq_mask_smooth_hz, time_mask_smooth_ms, thresh_n_mult_nonstationary, sigmoid_slope_nonstationary, n_std_thresh_stationary, tmp_folder, chunk_size, padding, n_fft, win_length, hop_length, clip_noise_stationary, use_tqdm, n_jobs, use_torch, device)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m         sg \u001b[38;5;241m=\u001b[39m SpectralGateNonStationary(\n\u001b[1;32m    168\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    169\u001b[0m             sr\u001b[38;5;241m=\u001b[39msr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    184\u001b[0m         )\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/noisereduce/spectralgate/base.py:206\u001b[0m, in \u001b[0;36mSpectralGate.get_traces\u001b[0;34m(self, start_frame, end_frame)\u001b[0m\n\u001b[1;32m    203\u001b[0m     end_list\u001b[38;5;241m.\u001b[39mappend(end0)\n\u001b[1;32m    204\u001b[0m     pos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m end0 \u001b[38;5;241m-\u001b[39m start0\n\u001b[0;32m--> 206\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterate_chunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiltered_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mich\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mich\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mich1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mich2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_chunk\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/noisereduce/spectralgate/base.py:163\u001b[0m, in \u001b[0;36mSpectralGate._iterate_chunk\u001b[0;34m(self, filtered_chunk, pos, end0, start0, ich)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iterate_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, filtered_chunk, pos, end0, start0, ich):\n\u001b[0;32m--> 163\u001b[0m     filtered_chunk0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_filtered_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mich\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     filtered_chunk[:, pos: pos \u001b[38;5;241m+\u001b[39m end0 \u001b[38;5;241m-\u001b[39m start0] \u001b[38;5;241m=\u001b[39m filtered_chunk0[:, start0:end0]\n\u001b[1;32m    165\u001b[0m     pos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m end0 \u001b[38;5;241m-\u001b[39m start0\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/noisereduce/spectralgate/base.py:156\u001b[0m, in \u001b[0;36mSpectralGate._get_filtered_chunk\u001b[0;34m(self, ind)\u001b[0m\n\u001b[1;32m    154\u001b[0m start0 \u001b[38;5;241m=\u001b[39m ind \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_size\n\u001b[1;32m    155\u001b[0m end0 \u001b[38;5;241m=\u001b[39m (ind \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_size\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend0\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/noisereduce/spectralgate/base.py:149\u001b[0m, in \u001b[0;36mSpectralGate.filter_chunk\u001b[0;34m(self, start_frame, end_frame)\u001b[0m\n\u001b[1;32m    147\u001b[0m i2 \u001b[38;5;241m=\u001b[39m end_frame \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding\n\u001b[1;32m    148\u001b[0m padded_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_chunk(i1, i2)\n\u001b[0;32m--> 149\u001b[0m filtered_padded_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filtered_padded_chunk[:, start_frame \u001b[38;5;241m-\u001b[39m i1: end_frame \u001b[38;5;241m-\u001b[39m i1]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/noisereduce/spectralgate/nonstationary.py:101\u001b[0m, in \u001b[0;36mSpectralGateNonStationary._do_filter\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Do the actual filtering\"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     chunk_filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectral_gating_nonstationary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunk_filtered\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/noisereduce/spectralgate/nonstationary.py:80\u001b[0m, in \u001b[0;36mSpectralGateNonStationary.spectral_gating_nonstationary\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m     72\u001b[0m sig_mask \u001b[38;5;241m=\u001b[39m sigmoid(\n\u001b[1;32m     73\u001b[0m     sig_mult_above_thresh,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thresh_n_mult_nonstationary,\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid_slope_nonstationary,\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_mask:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# convolve the mask with a smoothing filter\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     sig_mask \u001b[38;5;241m=\u001b[39m \u001b[43mfftconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smoothing_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m sig_mask \u001b[38;5;241m=\u001b[39m sig_mask \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prop_decrease \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mones(np\u001b[38;5;241m.\u001b[39mshape(sig_mask)) \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prop_decrease\n\u001b[1;32m     84\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# multiply signal with mask\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/signal/_signaltools.py:675\u001b[0m, in \u001b[0;36mfftconvolve\u001b[0;34m(in1, in2, mode, axes)\u001b[0m\n\u001b[1;32m    670\u001b[0m s2 \u001b[38;5;241m=\u001b[39m in2\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    672\u001b[0m shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m((s1[i], s2[i])) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m axes \u001b[38;5;28;01melse\u001b[39;00m s1[i] \u001b[38;5;241m+\u001b[39m s2[i] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    673\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(in1\u001b[38;5;241m.\u001b[39mndim)]\n\u001b[0;32m--> 675\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43m_freq_domain_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_fast_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_conv_mode(ret, s1, s2, mode, axes)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/signal/_signaltools.py:513\u001b[0m, in \u001b[0;36m_freq_domain_conv\u001b[0;34m(in1, in2, axes, shape, calc_fast_len)\u001b[0m\n\u001b[1;32m    510\u001b[0m     fft, ifft \u001b[38;5;241m=\u001b[39m sp_fft\u001b[38;5;241m.\u001b[39mfftn, sp_fft\u001b[38;5;241m.\u001b[39mifftn\n\u001b[1;32m    512\u001b[0m sp1 \u001b[38;5;241m=\u001b[39m fft(in1, fshape, axes\u001b[38;5;241m=\u001b[39maxes)\n\u001b[0;32m--> 513\u001b[0m sp2 \u001b[38;5;241m=\u001b[39m \u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43min2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m ret \u001b[38;5;241m=\u001b[39m ifft(sp1 \u001b[38;5;241m*\u001b[39m sp2, fshape, axes\u001b[38;5;241m=\u001b[39maxes)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calc_fast_len:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/fft/_backend.py:28\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/fft/_basic_backend.py:121\u001b[0m, in \u001b[0;36mrfftn\u001b[0;34m(x, s, axes, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrfftn\u001b[39m(x, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m           overwrite_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, plan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_nD\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrfftn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pocketfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfftn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/fft/_basic_backend.py:47\u001b[0m, in \u001b[0;36m_execute_nD\u001b[0;34m(func_str, pocketfft_func, x, s, axes, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_numpy(xp):\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpocketfft_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m norm \u001b[38;5;241m=\u001b[39m _validate_fft_args(workers, plan, norm)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:177\u001b[0m, in \u001b[0;36mr2cn\u001b[0;34m(forward, x, s, axes, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat least 1 axis must be transformed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Note: overwrite_x is not utilized\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr2c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import noisereduce\n",
    "\n",
    "directories = [\n",
    "    '../audio/0',\n",
    "    '../audio/1'\n",
    "]\n",
    "\n",
    "def create_metadata_df(directories):\n",
    "    data = []\n",
    "    for directory in directories:\n",
    "        for filename in os.listdir(directory):\n",
    "                \n",
    "            speaker_id, script_id, gender, recording_type = extract_from_filename(filename)\n",
    "            filepath = os.path.join(directory,filename)\n",
    "            y, sr = librosa.load(filepath,sr=None)\n",
    "            y=noisereduce.reduce_noise(y=y,sr=sr) # reducing noise, without it almost all audio is considered speech with based top_db being 60\n",
    "            duration = librosa.get_duration(y=y, sr=sr)\n",
    "            db = librosa.amplitude_to_db(y)\n",
    "            # print(np.max(abs(db))) #around 80\n",
    "    \n",
    "            # non_silent_intervals = librosa.effects.split(y)\n",
    "        \n",
    "            # Calculate the talking duration\n",
    "            # talking_duration = sum((end - start) / sr for start, end in non_silent_intervals)   \n",
    "            # silence_duration = duration - talking_duration\n",
    "    \n",
    "                # Compute RMSE (Root Mean Square Energy)\n",
    "            rmse = librosa.feature.rms(y=y).mean()  # Mean RMSE across frames\n",
    "            \n",
    "            # Compute ZCR (Zero Crossing Rate)\n",
    "            zcr = librosa.feature.zero_crossing_rate(y).mean()  # Mean ZCR across frames\n",
    "            \n",
    "            data.append({\n",
    "                'filename': filename,\n",
    "                'speaker_id': speaker_id,\n",
    "                'gender': gender,\n",
    "                'script_id': script_id,\n",
    "                'recording_type': recording_type,\n",
    "                'is_class_one': any(s in filename for s in class_one),\n",
    "                'path': filepath,\n",
    "                'duration': duration,\n",
    "                # 'talking_duration': talking_duration,\n",
    "                # 'silence_duration': silence_duration,\n",
    "                'RMSE': rmse,\n",
    "                'ZCR': zcr,\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "metadata_df = create_metadata_df(directories)\n",
    "print(metadata_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d7e61d3-0318-4d7a-88d0-ceeb1bcf3dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "<bound method NDFrame.head of Empty DataFrame\n",
      "Columns: []\n",
      "Index: []>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'RMSE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(metadata_df\u001b[38;5;241m.\u001b[39mhead)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(\u001b[43mmetadata_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRMSE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, hue\u001b[38;5;241m=\u001b[39mmetadata_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m], palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of RMSE by Gender\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRoot Mean Square Energy (RMSE)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'RMSE'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(data)\n",
    "metadata_df = pd.DataFrame(data)\n",
    "print(metadata_df.head)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(metadata_df['RMSE'], bins=30, kde=True, hue=metadata_df['gender'], palette='coolwarm')\n",
    "plt.title('Distribution of RMSE by Gender')\n",
    "plt.xlabel('Root Mean Square Energy (RMSE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(metadata_df['ZCR'], bins=30, kde=True, hue=metadata_df['gender'], palette='coolwarm')\n",
    "plt.title('Distribution of ZCR by Gender')\n",
    "plt.xlabel('Zero Crossing Rate (ZCR)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=metadata_df, x='speaker_id', y='RMSE', hue='is_class_one', palette='viridis')\n",
    "plt.title('RMSE by Speaker and Recording Type')\n",
    "plt.xlabel('Speaker ID')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=metadata_df, x='speaker_id', y='ZCR', hue='is_class_one', palette='viridis')\n",
    "plt.title('ZCR by Speaker and Recording Type')\n",
    "plt.xlabel('Speaker ID')\n",
    "plt.ylabel('ZCR')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(metadata_df['RMSE'], metadata_df['zcr'], alpha=0.5, c=metadata_df['is_class_one'], cmap='coolwarm')\n",
    "plt.title('Relationship between RMSE and ZCR')\n",
    "plt.xlabel('Root Mean Square Energy (RMSE)')\n",
    "plt.ylabel('Zero Crossing Rate (ZCR)')\n",
    "plt.colorbar(label='Recording Type (0/1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b429fd0-e1e3-478b-997a-bcc61e253a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Distribution of durations\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(metadata_df['duration'], bins=30, kde=True)\n",
    "plt.title('Distribution of Audio Durations')\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Distribution by speaker_id\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=metadata_df, x='speaker_id', order=metadata_df['speaker_id'].value_counts().index)\n",
    "plt.title('Number of Samples per Speaker')\n",
    "plt.xlabel('Speaker ID')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Extract average pixel intensity from spectrograms\n",
    "def extract_image_features(img_path):\n",
    "    img = Image.open(img_path).convert('L')  # Ensure grayscale\n",
    "    img_array = np.array(img)\n",
    "    avg_intensity = img_array.mean()\n",
    "    return avg_intensity\n",
    "\n",
    "metadata_df['avg_intensity'] = None\n",
    "\n",
    "for idx, row in metadata_df.iterrows():\n",
    "    img_path = os.path.join(directory, row['filename'].replace('.wav', '.png'))\n",
    "    metadata_df.at[idx, 'avg_intensity'] = extract_image_features(img_path)\n",
    "\n",
    "# Avg intensity distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(metadata_df['avg_intensity'], bins=30, kde=True)\n",
    "plt.title('Distribution of Average Pixel Intensity in Spectrograms')\n",
    "plt.xlabel('Average Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ordered_speakers = sorted(metadata_df['speaker_id'].unique())\n",
    "sns.boxplot(data=metadata_df,y='duration', x='speaker_id',hue='is_class_one',order=ordered_speakers,)\n",
    "plt.title('Duration by Speaker')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ordered_scripts = sorted(metadata_df['script_id'].unique())\n",
    "sns.boxplot(data=metadata_df,y='duration', x='script_id',order=ordered_scripts,)\n",
    "plt.title('Duration by Script')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot to visualize relationship(None?)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(metadata_df['duration'], metadata_df['avg_intensity'], alpha=0.5)\n",
    "plt.title('Correlation between Audio Duration and Spectrogram Intensity')\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.ylabel('Average Pixel Intensity')\n",
    "plt.show()\n",
    "\n",
    "p = metadata_df.pivot(index='speaker_id', columns='script_id', values='avg_intensity').fillna(0)\n",
    "\n",
    "# Avg Intensity Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(p, annot=True, cmap='YlGnBu', fmt='.2f')\n",
    "plt.title('Average Intensity by Speaker and Script')\n",
    "plt.xlabel('Script ID')\n",
    "plt.ylabel('Speaker ID')\n",
    "plt.show()\n",
    "\n",
    "silence_pivot = metadata_df.pivot(index='speaker_id', columns='script_id', values='silence_duration')\n",
    "talking_pivot = metadata_df.pivot(index='speaker_id', columns='script_id', values='talking_duration')\n",
    "\n",
    "#Probably choose one, both seem too much\n",
    "\n",
    "# Silence duration heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(silence_pivot, annot=True, cmap='YlGnBu', cbar_kws={'label': 'Silence Duration'})\n",
    "plt.title('Silence Duration by Speaker and Script')\n",
    "plt.show()\n",
    "\n",
    "# Talking duration heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(talking_pivot, annot=True, cmap='YlGnBu',fmt = '.4g', cbar_kws={'label': 'Talking Duration'})\n",
    "plt.title('Talking Duration by Speaker and Script')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metadata_df, x='speaker_id', y='silence_duration',hue='is_class_one')\n",
    "plt.title('Silence Duration by Speaker')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metadata_df, x='script_id', y='talking_duration')\n",
    "plt.title('Talking Duration by Script')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e70736fd-651b-41a7-ba65-6387fd635fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7454)\n",
      "tensor(0.2575)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# Dataset class\n",
    "class AudioSpectrogramDataset(Dataset):\n",
    "    def __init__(self, slices, labels, sample_rate=16000, transform=None):\n",
    "        self.slices = slices\n",
    "        self.labels = labels\n",
    "        self.sample_rate = sample_rate\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform = self.slices[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            spectrogram = self.transform(spectrogram)\n",
    "\n",
    "        return spectrogram, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    # Compute the mean and standard deviation of all pixels in the dataset\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum() * batch_size\n",
    "        std += images.std(axis=(0, 2, 3)).sum() * batch_size\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#../sliced_spectograms_no_silence/\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root='C:\\\\Users\\\\macie\\\\sliced_spectograms_no_silence\\\\',transform=transform)\n",
    "\n",
    "class_indices = {i: [] for i in range(len(full_dataset.classes))}\n",
    "for idx, (_, label) in enumerate(full_dataset.samples):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "# Balance by reducing the larger class\n",
    "min_class_count = min(len(indices) for indices in class_indices.values())\n",
    "balanced_indices = [random.sample(indices, min_class_count) for indices in class_indices.values()]\n",
    "\n",
    "# Flatten the list of balanced indices\n",
    "balanced_indices = [idx for indices in balanced_indices for idx in indices]\n",
    "\n",
    "# Create a balanced dataset\n",
    "balanced_dataset = torch.utils.data.Subset(full_dataset, balanced_indices)\n",
    "\n",
    "# class_labels = [label for _, label in balanced_dataset.samples]\n",
    "\n",
    "# # Count occurrences of each class\n",
    "# class_counts = Counter(class_labels)\n",
    "\n",
    "# # Display the counts\n",
    "# for class_idx, count in class_counts.items():\n",
    "#     print(f\"Class {class_idx} ({full_dataset.classes[class_idx]}): {count} samples\")\n",
    "    \n",
    "\n",
    "# # Count classes in the dataset\n",
    "# train_counts = Counter([label for _, label in train_subset])\n",
    "# test_counts = Counter([label for _, label in test_subset])\n",
    "\n",
    "# print(f\"Train Class Distribution: {train_counts}\")\n",
    "# print(f\"Test Class Distribution: {test_counts}\")\n",
    "\n",
    "loader = DataLoader(balanced_dataset, batch_size=32, shuffle=True,num_workers=4, pin_memory=True)\n",
    "mean, std = get_mean_std(loader)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.RandomCrop(INPUT_RESOLUTION), # added RandomCrop, no padding\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean,std=std)])\n",
    "\n",
    "normalized_dataset = datasets.ImageFolder(root='C:\\\\Users\\\\macie\\\\sliced_spectograms_no_silence\\\\',transform=transform)\n",
    "\n",
    "print(mean)\n",
    "print(std)\n",
    "\n",
    "images = list(range(len(normalized_dataset)))\n",
    "    \n",
    "\n",
    "# Split into training and testing\n",
    "# train_files, test_files = train_test_split(\n",
    "#     images,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "# Iterate through all samples to create indices based on the condition\n",
    "for i, (image, label) in enumerate(normalized_dataset):\n",
    "    file_path, _ = normalized_dataset.samples[i]  # `full_dataset.samples` is a list of (file_path, class) tuples\n",
    "    \n",
    "    if \"script5\" in os.path.basename(file_path):\n",
    "        test_indices.append(i)\n",
    "    else:\n",
    "        train_indices.append(i)\n",
    "\n",
    "# Create training and testing subsets based on indices\n",
    "train_subset = torch.utils.data.Subset(normalized_dataset, train_indices)\n",
    "test_subset = torch.utils.data.Subset(normalized_dataset, test_indices)\n",
    "\n",
    "# train_subset = torch.utils.data.Subset(full_dataset, train_files)\n",
    "# test_subset = torch.utils.data.Subset(full_dataset, test_files)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True) # change to 16? set workers to number of cpu cores ot less\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c1b4d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # Should print True\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())  # Number of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9469ff2-d84b-4432-9bdd-15701d733bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "INPUT_RESOLUTION=128\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 60, 5) #*10/ if overfit drop/ one layer + pooling\n",
    "        self.bn1 = nn.BatchNorm2d(60) # added batch norm\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(60, 160, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(160) # my bad, it over written first batchnorm\n",
    "        self.fc1 = nn.Linear(160 * (INPUT_RESOLUTION//4 -2 ) * (INPUT_RESOLUTION//4 - 2), 1200)\n",
    "        self.fc2 = nn.Linear(1200, 840)\n",
    "        self.fc3 = nn.Linear(840, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d787e49b-7355-46cf-8bf7-40018b4640f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "LEARNING_RATE = 0.0001 # 0.005 standard, trying lwoer for Adam\n",
    "LR_DECAY = 0.95\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr = LEARNING_RATE, momentum = MOMENTUM)\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=LR_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "num_learnable_parameters = sum([\n",
    "    p.numel() for p in net.parameters() if p.requires_grad\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef886a54-9895-43e8-aa75-f08bfce0cc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4a7c57ui) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632375b7ad234d9db340dd863f7a50e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>validation/accuracy</td><td></td></tr><tr><td>validation/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>0.5175</td></tr><tr><td>train/loss</td><td>0.69265</td></tr><tr><td>validation/accuracy</td><td>0.50359</td></tr><tr><td>validation/loss</td><td>0.6934</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-fire-36</strong> at: <a href='https://wandb.ai/imlproject79-politechnika-warszawska/IML/runs/4a7c57ui' target=\"_blank\">https://wandb.ai/imlproject79-politechnika-warszawska/IML/runs/4a7c57ui</a><br/> View project at: <a href='https://wandb.ai/imlproject79-politechnika-warszawska/IML' target=\"_blank\">https://wandb.ai/imlproject79-politechnika-warszawska/IML</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241127_021143-4a7c57ui\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4a7c57ui). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\ML\\IML-project\\wandb\\run-20241127_083950-wcd7fvzv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imlproject79-politechnika-warszawska/IML/runs/wcd7fvzv' target=\"_blank\">fast-pine-37</a></strong> to <a href='https://wandb.ai/imlproject79-politechnika-warszawska/IML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imlproject79-politechnika-warszawska/IML' target=\"_blank\">https://wandb.ai/imlproject79-politechnika-warszawska/IML</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imlproject79-politechnika-warszawska/IML/runs/wcd7fvzv' target=\"_blank\">https://wandb.ai/imlproject79-politechnika-warszawska/IML/runs/wcd7fvzv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/imlproject79-politechnika-warszawska/IML/runs/wcd7fvzv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1968e23e420>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# wandb.login()\n",
    "wandb.init(\n",
    "    project=\"IML\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        # \"learning_rate_decay\": LR_DECAY,\n",
    "        \"batch_size\": train_loader.batch_size,\n",
    "        \"input_resolution\": INPUT_RESOLUTION,\n",
    "        \"num_parameters\": num_learnable_parameters,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"DAPS\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8698613a-1f3c-4b9e-b936-f1801000f5a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "[1,   416] loss: 0.632159193\n",
      "[1,   832] loss: 0.366170864\n",
      "[1,  1248] loss: 0.266297430\n",
      "[1,  1664] loss: 0.198011131\n",
      "[1,  2080] loss: 0.143242020\n",
      "[2,   416] loss: 0.099902239\n",
      "[2,   832] loss: 0.096119894\n",
      "[2,  1248] loss: 0.081816411\n",
      "[2,  1664] loss: 0.077823392\n",
      "[2,  2080] loss: 0.078226871\n",
      "[3,   416] loss: 0.044815646\n",
      "[3,   832] loss: 0.044396274\n",
      "[3,  1248] loss: 0.051171659\n",
      "[3,  1664] loss: 0.042470166\n",
      "[3,  2080] loss: 0.033598759\n",
      "[4,   416] loss: 0.025653114\n",
      "[4,   832] loss: 0.038317447\n",
      "[4,  1248] loss: 0.028860427\n",
      "[4,  1664] loss: 0.027131387\n",
      "[4,  2080] loss: 0.033548149\n",
      "[5,   416] loss: 0.021239929\n",
      "[5,   832] loss: 0.019102972\n",
      "[5,  1248] loss: 0.022238309\n",
      "[5,  1664] loss: 0.016945752\n",
      "[5,  2080] loss: 0.022738239\n",
      "[6,   416] loss: 0.016520440\n",
      "[6,   832] loss: 0.023089007\n",
      "[6,  1248] loss: 0.011843452\n",
      "[6,  1664] loss: 0.021625287\n",
      "[6,  2080] loss: 0.018248921\n",
      "[7,   416] loss: 0.009318597\n",
      "[7,   832] loss: 0.013802004\n",
      "[7,  1248] loss: 0.011948850\n",
      "[7,  1664] loss: 0.023068272\n",
      "[7,  2080] loss: 0.016542993\n",
      "[8,   416] loss: 0.008435996\n",
      "[8,   832] loss: 0.013373957\n",
      "[8,  1248] loss: 0.009986202\n",
      "[8,  1664] loss: 0.016003816\n",
      "[8,  2080] loss: 0.011859390\n",
      "[9,   416] loss: 0.010538194\n",
      "[9,   832] loss: 0.012295614\n",
      "[9,  1248] loss: 0.011262672\n",
      "[9,  1664] loss: 0.008103657\n",
      "[9,  2080] loss: 0.015861603\n",
      "[10,   416] loss: 0.009594486\n",
      "[10,   832] loss: 0.005150112\n",
      "[10,  1248] loss: 0.012997185\n",
      "[10,  1664] loss: 0.006702339\n",
      "[10,  2080] loss: 0.005840584\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>validation/accuracy</td><td></td></tr><tr><td>validation/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>0.99805</td></tr><tr><td>train/loss</td><td>0.00584</td></tr><tr><td>validation/accuracy</td><td>0.98291</td></tr><tr><td>validation/loss</td><td>0.06251</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-pine-37</strong> at: <a href='https://wandb.ai/imlproject79-politechnika-warszawska/IML/runs/wcd7fvzv' target=\"_blank\">https://wandb.ai/imlproject79-politechnika-warszawska/IML/runs/wcd7fvzv</a><br/> View project at: <a href='https://wandb.ai/imlproject79-politechnika-warszawska/IML' target=\"_blank\">https://wandb.ai/imlproject79-politechnika-warszawska/IML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241127_083950-wcd7fvzv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "PRINT_STEP = len(train_loader) // 5 - 1\n",
    "# Initialize counters\n",
    "correct_class_0 = 0  \n",
    "incorrect_class_0 = 0  \n",
    "correct_class_1 = 0  \n",
    "incorrect_class_1 = 0 \n",
    "\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "\n",
    "# Counters for total samples in each class\n",
    "total_class_0 = 0\n",
    "total_class_1 = 0\n",
    "print('Starting Training')\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    scaler = torch.GradScaler('cuda') if torch.cuda.is_available() else None    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        #trying mixed precision training for better performance\n",
    "        if (scaler):\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)# Automatically casts to lower precision\n",
    "            scaler.scale(loss).backward()  # Scales gradients\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        correct += (predictions == labels).float().mean().item()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % PRINT_STEP == PRINT_STEP-1: \n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / PRINT_STEP:.9f}')\n",
    "\n",
    "            accuracy = correct / PRINT_STEP\n",
    "            loss = running_loss / PRINT_STEP\n",
    "            step = epoch * len(train_loader) + i\n",
    "            wandb.log({\n",
    "                    \"train/accuracy\": accuracy,\n",
    "                    \"train/loss\": loss\n",
    "                },\n",
    "                step=step\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "\n",
    "    net.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for j, data in enumerate(test_loader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            test_correct += (predictions == labels).float().mean().item()\n",
    "            \n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == 0:\n",
    "                    total_class_0 += 1\n",
    "                    if prediction == 0:\n",
    "                        true_negative += 1\n",
    "                        correct_class_0 += 1\n",
    "                    else:\n",
    "                        incorrect_class_0 += 1  # False Acceptance\n",
    "                        false_positive += 1\n",
    "                elif label == 1:\n",
    "                    total_class_1 += 1\n",
    "                    if prediction == 1:\n",
    "                        correct_class_1 += 1\n",
    "                        true_positive += 1\n",
    "                    else:\n",
    "                        incorrect_class_1 += 1  # False Rejection\n",
    "                        false_negative += 1\n",
    "\n",
    "    accuracy = test_correct / len(test_loader)\n",
    "    loss = test_loss / len(test_loader)\n",
    "    wandb.log({\n",
    "            \"validation/accuracy\": accuracy,\n",
    "            \"validation/loss\": loss\n",
    "        },\n",
    "        step = (epoch + 1) * len(train_loader)\n",
    "    )\n",
    "    net.train()\n",
    "    scheduler.step(test_loss) # test_loss parameter\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "PATH = './net6.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aba8d182-2a6e-4fbc-9717-066e2d16a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Acceptance Ratio (FAR): 2.88%\n",
      "False Rejection Ratio (FRR): 3.55%\n",
      "Sensitivity : 96.45%\n",
      "Specificity : 97.12%\n",
      "Precision : 97.13%\n",
      "Accuracy : 96.78%\n",
      "Negative Predict Value : 96.97%\n",
      "F-1 score: : 96.79%\n",
      "Accuracy of the network on the test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "if total_class_0 > 0:\n",
    "    far = incorrect_class_0 / total_class_0\n",
    "else:\n",
    "    far = None  # handle division by zero if there are no samples for Class 0\n",
    "\n",
    "if total_class_1 > 0:\n",
    "    frr = incorrect_class_1 / total_class_1\n",
    "else:\n",
    "    frr = None  # handle division by zero if there are no samples for Class 1\n",
    "#Try torch metrics for cleaner code\n",
    "print(f\"False Acceptance Ratio (FAR): {far:.2%}\")\n",
    "print(f\"False Rejection Ratio (FRR): {frr:.2%}\")\n",
    "print(f\"Sensitivity : {true_positive/(true_positive+false_negative):.2%}\")\n",
    "print(f\"Specificity : {true_negative/(true_negative+false_positive):.2%}\")\n",
    "print(f\"Precision : {true_positive/(true_positive+false_positive):.2%}\")\n",
    "print(f\"Accuracy : {(true_positive+true_negative)/(true_positive+false_positive+true_negative+false_negative):.2%}\")\n",
    "print(f\"Negative Predict Value : {true_positive/(true_negative+false_negative):.2%}\")\n",
    "# print(f\": : {}\")\n",
    "\n",
    "print(f\"F-1 score: : {2*true_positive/(2*true_positive+false_positive+false_negative):.2%}\")\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * (correct_class_0+correct_class_1) // (total_class_0+total_class_1)} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
